# InternLM实战营第二期第一课笔记-书生·浦语大模型全链路开源体系


### 一、书生·浦语大模型开源体系
- **介绍**: 书生·浦语大模型是一个全年度开源体系，包含轻量级和重量级模型，覆盖不同能力。
- **发展历程**: 展示了书生·浦语大模型的发展历程和特点。
- **多语言多模态**: 书生·浦语大模型2.0支持多语言和多模态任务。

### 二、模型能力评测
- **性能对比**: 20B模型在推理、数学、代码等方面性能优于GPT-3.5和Gemini Pro。
- **领先水平**: 在综合性能方面，模型达到同量级开源模型的领先水平。
- **计算与数据分析**: 模型具备内生的计算能力和数据分析功能，能够处理复杂任务。

### 三、模型选型与应用流程
- **模型选型**: 考虑模型复杂度和算力，是应用的第一步。
- **全链条工具体系**: 书生·浦语提供从数据到应用的全链条工具体系，全部开源。
- **数据集开源**: 书生万卷cc数据集，涵盖2013年至2023年互联网公开内容，经过清洗和处理。

### 四、Open Compass 2.0评测体系
- **评测框架**: 开发并开源了评测框架，建立了评测基准社区。
- **能力提升分析**: Open Compass 2.0帮助分析大模型能力提升。
- **适配评测集**: 已经适配超过100个评测集，是国内最完善的评测体系之一。

### 五、模型推理和部署工具
- **社区发展趋势**: 中轻量级模型性能接近商业闭源模型。
- **Mdepot**: 提供全链条部署解决方案，支持模型轻量化、推理引擎、服务模块等。
- **智能体框架Legend**: 支持多种智能体能力，提供多模态AI工具箱AgentLego和多媒体算法功能。

### 个人感想
视频内容全面介绍了书生·浦语大模型的开源体系和应用，从模型选型到应用的整个流程，以及评测体系的建立和工具的开发。特别是Open Compass 2.0的介绍，为大模型的能力评测和优化提供了有力的支持。此外，Mdepot和Legend框架的介绍，展示了开源社区在模型部署和智能体开发方面的进步，为AI技术的进一步研究和应用提供了便利。

### 附加信息
- **GitHub链接**: [https://github.com/InternLM/InternLM/](https://github.com/InternLM/InternLM/)


## 论文学习笔记

这篇论文介绍了一个名为InternLM2的开源大型语言模型（LLM），它在多个维度和基准测试中表现出色，并且在长文本建模和开放式主观评估中通过创新的预训练和优化技术超越了其前身。以下是对这篇论文的学习笔记：

### 1. InternLM2概述
- **背景**: 大型语言模型（LLMs）如ChatGPT和GPT-4的出现引发了关于人工通用智能（AGI）的讨论。然而，复制这些模型在开源模型中的进步一直是一个挑战。
- **InternLM2**: 一个开源的LLM，通过综合评估在6个维度和30个基准测试中超越了其前身，并且在长文本建模和开放式主观评估中表现出色。

### 2. InternLM2的关键特性
- **多维度性能**: 在多个领域和任务中表现出色。
- **长文本建模**: 能够高效捕捉长期依赖关系，最初在4k令牌上训练，然后提升到32k令牌的预训练和微调阶段。
- **优化技术**: 采用了创新的预训练和优化技术，包括监督式微调（SFT）和条件在线强化学习（COOL RLHF）策略。

### 3. 预训练过程
- **数据类型**: 包括文本、代码和长文本数据。
- **令牌化**: 使用GPT-4的令牌化方法，优化了模型的压缩效率。
- **超参数**: 根据模型大小调整了学习率、批量大小等超参数。

### 4. 对齐（Alignment）
- **监督式微调（SFT）**: 使用高质量的指令数据集进行微调，以确保模型遵循多样化的人类指令。
- **COOL RLHF**: 引入条件奖励模型来解决冲突的人类偏好问题，并执行多轮在线RLHF以减少奖励黑客攻击。

### 5. 评估与分析
- **下游任务性能**: 在多个NLP任务上进行了评估，包括综合考试、语言和知识、推理和数学、编程等。
- **对齐性能**: 在多个主观评估数据集上进行了评估，展示了模型与人类偏好的一致性。

### 6. 数据污染讨论
- **数据集评估**: 对模型在GSM8K数据集上的潜在测试数据泄露和过拟合进行了评估。

### 7. 结论
- **InternLM2**: 展示了在主观和客观评估中的卓越性能。
- **开源**: 提供了不同训练阶段和大小的模型，为社区提供了模型演化的洞察。

### 8. 附录
- **致谢**: 对参与项目的贡献者表示感谢。
- **评估提示**: 提供了用于评估的示例提示。

### 个人感想
InternLM2的开源为研究社区提供了一个强大的工具，有助于推动LLMs的发展。它在长文本建模和对齐方面的创新技术，为构建更加智能和可靠的AI系统提供了新的可能性。此外，论文中对预训练数据的详细描述和评估方法的透明性，为未来的研究提供了宝贵的指导。